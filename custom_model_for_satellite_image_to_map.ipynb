{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T22:35:33.839332Z",
     "iopub.status.busy": "2025-06-14T22:35:33.838663Z",
     "iopub.status.idle": "2025-06-14T22:35:36.645218Z",
     "shell.execute_reply": "2025-06-14T22:35:36.644377Z",
     "shell.execute_reply.started": "2025-06-14T22:35:33.839300Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os, torch, torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T22:35:36.646817Z",
     "iopub.status.busy": "2025-06-14T22:35:36.646438Z",
     "iopub.status.idle": "2025-06-14T22:35:39.405042Z",
     "shell.execute_reply": "2025-06-14T22:35:39.404266Z",
     "shell.execute_reply.started": "2025-06-14T22:35:36.646786Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, normalize=True):\n",
    "        super().__init__()\n",
    "        layers = [nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False)]\n",
    "        if normalize:\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout=0.0):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class GeneratorUNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super().__init__()\n",
    "        self.down1 = DownBlock(in_channels, 256, normalize=False)\n",
    "        self.down2 = DownBlock(256, 512)\n",
    "        self.down3 = DownBlock(512, 1024)\n",
    "        self.down4 = DownBlock(1024, 1024)\n",
    "        self.down5 = DownBlock(1024, 1024)\n",
    "        self.down6 = DownBlock(1024, 1024)\n",
    "        self.down7 = DownBlock(1024, 1024)\n",
    "        self.down8 = DownBlock(1024, 1024, normalize=False)\n",
    "\n",
    "        self.up1 = UpBlock(1024, 1024, dropout=0.5)\n",
    "        self.up2 = UpBlock(2048, 1024, dropout=0.5)\n",
    "        self.up3 = UpBlock(2048, 1024, dropout=0.5)\n",
    "        self.up4 = UpBlock(2048, 1024)\n",
    "        self.up5 = UpBlock(2048, 1024)\n",
    "        self.up6 = UpBlock(2048, 512)\n",
    "        self.up7 = UpBlock(1024, 256)\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, out_channels, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)\n",
    "        d6 = self.down6(d5)\n",
    "        d7 = self.down7(d6)\n",
    "        d8 = self.down8(d7)\n",
    "\n",
    "        u1 = self.up1(d8)\n",
    "        u2 = self.up2(torch.cat([u1, d7], 1))\n",
    "        u3 = self.up3(torch.cat([u2, d6], 1))\n",
    "        u4 = self.up4(torch.cat([u3, d5], 1))\n",
    "        u5 = self.up5(torch.cat([u4, d4], 1))\n",
    "        u6 = self.up6(torch.cat([u5, d3], 1))\n",
    "        u7 = self.up7(torch.cat([u6, d2], 1))\n",
    "        return self.final(torch.cat([u7, d1], 1))\n",
    "\n",
    "class PatchDiscriminator(nn.Module):\n",
    "    def __init__(self, in_channels=6):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels, 128, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1024, 4, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(1024, 1, 4, 1, 1)\n",
    "        ]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return self.model(torch.cat([x, y], dim=1))\n",
    "\n",
    "class Pix2PixDataset(Dataset):\n",
    "    def __init__(self, root_dir, image_size=256):\n",
    "        self.files = [os.path.join(root_dir, f) for f in os.listdir(root_dir)\n",
    "                      if f.endswith(('.png','.jpg','.jpeg'))]\n",
    "        tf = [transforms.Resize((image_size, image_size)),\n",
    "              transforms.ToTensor(),\n",
    "              transforms.Normalize([0.5]*3, [0.5]*3)]\n",
    "        self.transform = transforms.Compose(tf)\n",
    "\n",
    "    def __len__(self): return len(self.files)\n",
    "    def __getitem__(self, i):\n",
    "        img = Image.open(self.files[i]).convert(\"RGB\")\n",
    "        w = img.width // 2\n",
    "        sat = self.transform(img.crop((0, 0, w, img.height)))\n",
    "        mapp = self.transform(img.crop((w, 0, img.width, img.height)))\n",
    "        return sat, mapp\n",
    "\n",
    "os.makedirs(\"/kaggle/working/samples\", exist_ok=True)\n",
    "os.makedirs(\"/kaggle/working/checkpoints\", exist_ok=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "gen = GeneratorUNet().to(device)\n",
    "disc = PatchDiscriminator().to(device)\n",
    "opt_g = optim.Adam(gen.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "opt_d = optim.Adam(disc.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "bce = nn.BCEWithLogitsLoss()\n",
    "l1 = nn.L1Loss()\n",
    "lambda_l1 = 100\n",
    "\n",
    "train = Pix2PixDataset(\"/kaggle/input/pix2pix-maps/train\", image_size=256)\n",
    "val = Pix2PixDataset(\"/kaggle/input/pix2pix-maps/val\", image_size=256)\n",
    "loader = DataLoader(train, batch_size=8, shuffle=True, num_workers=2, pin_memory=True)\n",
    "valloader = DataLoader(val, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T22:35:39.406339Z",
     "iopub.status.busy": "2025-06-14T22:35:39.406077Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.768, g_loss=12]  \n",
      "Epoch 2/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.0413, g_loss=15.8] \n",
      "Epoch 3/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.0314, g_loss=16.2]\n",
      "Epoch 4/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.0236, g_loss=14]   \n",
      "Epoch 5/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.00555, g_loss=16.9]\n",
      "Epoch 6/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.00142, g_loss=17.7]\n",
      "Epoch 7/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.0851, g_loss=13.7] \n",
      "Epoch 8/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.325, g_loss=17.2]  \n",
      "Epoch 9/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.0146, g_loss=16.9] \n",
      "Epoch 10/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.278, g_loss=10.9] \n",
      "Epoch 11/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.00704, g_loss=15.1]\n",
      "Epoch 12/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.0174, g_loss=14.1] \n",
      "Epoch 13/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.0209, g_loss=17.8] \n",
      "Epoch 14/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.0739, g_loss=12.2]\n",
      "Epoch 15/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.0225, g_loss=13.1] \n",
      "Epoch 16/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.0705, g_loss=13]  \n",
      "Epoch 17/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=1.45, g_loss=11.9]    \n",
      "Epoch 18/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.175, g_loss=12.3] \n",
      "Epoch 19/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.0239, g_loss=15.8] \n",
      "Epoch 20/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.161, g_loss=11.8] \n",
      "Epoch 21/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.148, g_loss=10.2]  \n",
      "Epoch 22/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.00115, g_loss=15.5]\n",
      "Epoch 23/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.202, g_loss=11.2]  \n",
      "Epoch 24/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.0909, g_loss=13.2] \n",
      "Epoch 25/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.258, g_loss=11.4]  \n",
      "Epoch 26/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.35, g_loss=14.4]   \n",
      "Epoch 27/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.0159, g_loss=12.2] \n",
      "Epoch 28/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.256, g_loss=11.2]  \n",
      "Epoch 29/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.186, g_loss=12.3]\n",
      "Epoch 30/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.177, g_loss=11.6] \n",
      "Epoch 31/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.0241, g_loss=12.3] \n",
      "Epoch 32/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.73, g_loss=9.05]   \n",
      "Epoch 33/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.00794, g_loss=13.1]\n",
      "Epoch 34/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.877, g_loss=16.8]   \n",
      "Epoch 35/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.509, g_loss=11.7]\n",
      "Epoch 36/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.926, g_loss=8.78] \n",
      "Epoch 37/50: 100%|██████████| 137/137 [02:01<00:00,  1.13it/s, d_loss=0.04, g_loss=10.5]   \n",
      "Epoch 38/50:  11%|█         | 15/137 [00:13<01:48,  1.13it/s, d_loss=1.43, g_loss=8.2]   "
     ]
    }
   ],
   "source": [
    "for epoch in range(300):\n",
    "    gen.train(); disc.train()\n",
    "    loop = tqdm(loader, f\"Epoch {epoch+1}/50\")\n",
    "    for sat, mapp in loop:\n",
    "        sat, mapp = sat.to(device), mapp.to(device)\n",
    "\n",
    "        fake = gen(sat)\n",
    "        real_pred = disc(sat, mapp)\n",
    "        fake_pred = disc(sat, fake.detach())\n",
    "        d_loss = (bce(real_pred, torch.ones_like(real_pred)) +\n",
    "                  bce(fake_pred, torch.zeros_like(fake_pred))) * 0.5\n",
    "        opt_d.zero_grad(); d_loss.backward(); opt_d.step()\n",
    "\n",
    "        fake_pred = disc(sat, fake)\n",
    "        g_adv = bce(fake_pred, torch.ones_like(fake_pred))\n",
    "        g_l1 = l1(fake, mapp) * lambda_l1\n",
    "        g_loss = g_adv + g_l1\n",
    "        opt_g.zero_grad(); g_loss.backward(); opt_g.step()\n",
    "\n",
    "        loop.set_postfix(d_loss=d_loss.item(), g_loss=g_loss.item())\n",
    "\n",
    "    gen.eval()\n",
    "    with torch.no_grad():\n",
    "        sat, real = next(iter(valloader))\n",
    "        sat, real = sat.to(device), real.to(device)\n",
    "        fake = gen(sat)\n",
    "        grid = make_grid(torch.cat([sat, fake, real], dim=0).cpu(), nrow=1, normalize=True)\n",
    "        save_image(grid, f\"/kaggle/working//samples/epoch_{epoch+1}.png\")\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        torch.save(gen.state_dict(), f\"/kaggle/working//checkpoints/gen_epoch_{epoch+1}.pth\")\n",
    "\n",
    "print(\"Training has ben ended!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 795438,
     "sourceId": 1365054,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
